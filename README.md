# RAG-LLM-LangChain-Groq
Retrieval-Augmented Generation (RAG) LLM using LangChain, Hugging Face &amp; Groq API ðŸ”¹ Fast &amp; accurate document-based Q&amp;A system with vector search &amp; high-speed inference.


ðŸ“Œ Overview
This project implements a Retrieval-Augmented Generation (RAG) pipeline using:

LangChain for orchestration

Hugging Face embeddings for better text representation

Groq API for high-speed inference

ChromaDB for efficient vector search

The script processes documents, stores embeddings in a vector database, and enables intelligent querying.
